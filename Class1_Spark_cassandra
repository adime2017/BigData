Read Cassandra
------------------------
Read from a cassandra table:

val tableToLoad=sqlContext
        .read
        .format("org.apache.spark.sql.cassandra")
        .options(Map("table"->"words_new","Keyspace"->"test_keyspace","inferSchema"->"true","cluster"-> "Test Cluster"))
        .load()
 
 inferSchema and cluster are optional
 
 You can ceate TempTable from the table loaded.
 
 val unit=tableToLoad.registerTempTable(tableName)
 
 Dataframe Read table Using Helper Function
 
 val df2 = spark
  .read
  .cassandraFormat("words_new", "test_keyspace", "Test Cluster")
  .load()
  
  Write to Cassandra
  -------------------------
  //Create a sample dataframe that is going to be written in Cassandra table
import org.apache.spark.sql.functions._
val employee1 = spark.range(0, 3).select($"id".as("id"), (rand() * 3).cast("int").as("dep_id"), (rand() * 40 + 20).cast("int").as("age"))

import org.apache.spark.sql.cassandra._

  employee1.write
  .format("org.apache.spark.sql.cassandra")
  .mode("overwrite")
  .options(Map( "table" -> "employee_new", "keyspace" -> "test_keyspace"))
  .save()
  
  NOTE: Different mode for spark cassandra:
  
If the cassandra table that spark targets exists then

Link for reference:
https://gist.github.com/kyrsideris/78c8c0ca73a72a92f009dcb540f0e1df

SaveMode.Append will update it
SaveMode.Overwrite will truncate and insert (but it requires option "confirm.truncate" -> "true")
SaveMode.Ignore will not perform any action on existing table
SaveMode.ErrorIfExists (default) will throw the following 
exception: https://github.com/datastax/spark-cassandra-connector/blob/v2.0.6/spark-cassandra-connector/src/main/scala/org/apache/spark/sql/cassandra/DefaultSource.scala#L93-L96
 
 Append: It will update the data and insert new record if any.
 Overwrite: It will truncate the table and load the data which we have passed.Fresh load.
 Ignore : It will not performa any operation.
 ErrorIfExists : Give error if the table already contains data.
 
 Overwirte example
 ---------------------
 For overwrite we need to use "confirm.truncate" when saving.
Exapmle:
ase class Person(name: String, surname: String, children: Int)
val newNames = spark.sparkContext.parallelize(Seq(Person("Eleni", "Garcia", 1), Person("Galina", "Xin", 2), Person("Carlo", "Tran", 1)))
.toDS
newNames.write.format("org.apache.spark.sql.cassandra")
.options(Map("table" -> "people", "keyspace" -> "test_savemodes", "confirm.truncate" -> "true")).
mode(org.apache.spark.sql.SaveMode.Overwrite).save

  
  applyNullCheck(finalResultSet).write
  .format("org.apache.spark.sql.cassandra")
  .mode("overwrite")
  .options(Map( "table" -> "employee_new", "keyspace" -> "test_keyspace"))
  .save()
  Note: We can also apply some function to check if null is there and discard those records. We have created a applyNullCheck function
  to check for null.
  
